#!/usr/bin/env python3
"""
Quick comprehensive data import - optimized version
"""

import pandas as pd
import requests
import json
from datetime import date

SUPABASE_URL = "https://uddmjjgnexdazfedrytt.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InVkZG1qamduZXhkYXpmZWRyeXR0Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDc3NjQ2OTUsImV4cCI6MjA2MzM0MDY5NX0.A_034WOQ-JJ3DDvMux5fLXayJ4pUk3_WXnVTJI-wSL0"

headers = {
    'apikey': SUPABASE_KEY,
    'Authorization': f'Bearer {SUPABASE_KEY}',
    'Content-Type': 'application/json',
    'Prefer': 'return=minimal'
}

def safe_float(value, default=0.0):
    """Safely convert to float"""
    try:
        if pd.isna(value) or value == '' or value is None:
            return default
        return float(value)
    except:
        return default

def import_key_fields_only():
    """Import only the key fields we need for UI display"""
    print("ðŸ“Š Quick Import - Key Fields Only")
    print("=" * 50)
    
    # Get network and source mappings once
    networks = requests.get(f"{SUPABASE_URL}/rest/v1/networks", headers=headers).json()
    network_map = {n['tadig']: n['id'] for n in networks}
    
    sources = requests.get(f"{SUPABASE_URL}/rest/v1/pricing_sources", headers=headers).json()
    source_map = {s['source_name']: s['id'] for s in sources}
    
    # Get existing pricing records
    all_pricing = []
    offset = 0
    while True:
        headers_with_range = {**headers, 'Range': f'{offset}-{offset+999}'}
        response = requests.get(f"{SUPABASE_URL}/rest/v1/network_pricing", headers=headers_with_range)
        if response.status_code == 200:
            data = response.json()
            if not data:
                break
            all_pricing.extend(data)
            if len(data) < 1000:
                break
            offset += 1000
        else:
            break
    
    # Create lookup for existing records
    existing_map = {}
    for p in all_pricing:
        key = f"{p['network_id']}|{p['source_id']}"
        existing_map[key] = p['id']
    
    print(f"Found {len(existing_map)} existing pricing records")
    
    # Import Tele2 SMS data
    print("\nðŸ“„ Importing Tele2 SMS and restrictions...")
    try:
        df = pd.read_excel('0- Invoice Monogoto 2025-04.xlsx', sheet_name='Pricelist 2024-11-01', header=0)
        
        updates = []
        for _, row in df.iterrows():
            tadig = str(row.get('TADIG', '')).strip()
            if tadig in network_map:
                key = f"{network_map[tadig]}|{source_map['Tele2']}"
                if key in existing_map:
                    update = {
                        'sms_mo': safe_float(row.get('SMS', 0)),
                        'sms_mt': safe_float(row.get('SMS', 0))  # Tele2 has single SMS price
                    }
                    
                    # Add restriction if exists
                    comment = row.get('Comments', '')
                    if pd.notna(comment) and comment:
                        comment = str(comment).strip()
                        if comment.lower() not in ['access fee', 'direct roaming', '']:
                            update['restrictions'] = comment
                    
                    updates.append((existing_map[key], update))
        
        # Batch update
        for pricing_id, update in updates[:100]:  # Limit to 100 for speed
            requests.patch(
                f"{SUPABASE_URL}/rest/v1/network_pricing?id=eq.{pricing_id}",
                headers=headers,
                json=update
            )
        
        print(f"  Updated {min(len(updates), 100)} Tele2 records with SMS data")
    except Exception as e:
        print(f"  Error: {e}")
    
    # Import A1 technology flags
    print("\nðŸ“˜ Importing A1 SMS and IoT technologies...")
    try:
        df = pd.read_excel('202509_Country Price List A1 IMSI Sponsoring.xlsx', sheet_name='prices A1 WS', header=7)
        
        updates = []
        for _, row in df.iterrows():
            tadig = str(row.get('TADIG', '')).strip()
            if tadig in network_map:
                key = f"{network_map[tadig]}|{source_map['A1']}"
                if key in existing_map:
                    update = {
                        'sms_mo': safe_float(row.get('SMS_MO', 0)),
                        'sms_mt': safe_float(row.get('SMS_MT', 0)),
                        'lte_m': str(row.get('LTE-M', 'No')).lower() in ['yes', 'available'],
                        'nb_iot': str(row.get('nb-IoT', 'No')).lower() in ['yes', 'available']
                    }
                    
                    # Add restriction if exists
                    restriction = row.get('Restrictions', '')
                    if pd.notna(restriction) and restriction:
                        update['restrictions'] = str(restriction).strip()
                    
                    updates.append((existing_map[key], update))
        
        # Batch update
        for pricing_id, update in updates[:100]:  # Limit to 100 for speed
            requests.patch(
                f"{SUPABASE_URL}/rest/v1/network_pricing?id=eq.{pricing_id}",
                headers=headers,
                json=update
            )
        
        print(f"  Updated {min(len(updates), 100)} A1 records with SMS and IoT data")
    except Exception as e:
        print(f"  Error: {e}")
    
    # Import Telefonica technology flags
    print("\nðŸ“™ Importing Telefonica SMS and IoT technologies...")
    try:
        df = pd.read_excel('20250205 Monogoto TGS UK V1.xlsx', sheet_name='Format All', header=0)
        
        updates = []
        for _, row in df.iterrows():
            tadig = str(row.get('Tadig', '')).strip()
            if tadig in network_map:
                key = f"{network_map[tadig]}|{source_map['Telefonica']}"
                if key in existing_map:
                    update = {
                        'sms_mo': safe_float(row.get('SMS', 0)),
                        'sms_mt': safe_float(row.get('SMS', 0)),  # Telefonica has single SMS price
                        'lte_m': row.get('LTE-M') == 'Available',
                        'nb_iot': row.get('NB-IoT') == 'Available'
                    }
                    
                    # Build restrictions from unavailable services
                    restrictions = []
                    if row.get('VoLTE') == 'Unavailable':
                        restrictions.append('VoLTE unavailable')
                    if row.get('LTE-M') == 'Unavailable':
                        restrictions.append('LTE-M unavailable')
                    if row.get('NB-IoT') == 'Unavailable':
                        restrictions.append('NB-IoT unavailable')
                    
                    if restrictions:
                        update['restrictions'] = ', '.join(restrictions)
                    
                    updates.append((existing_map[key], update))
        
        # Batch update
        for pricing_id, update in updates[:100]:  # Limit to 100 for speed
            requests.patch(
                f"{SUPABASE_URL}/rest/v1/network_pricing?id=eq.{pricing_id}",
                headers=headers,
                json=update
            )
        
        print(f"  Updated {min(len(updates), 100)} Telefonica records with SMS and IoT data")
    except Exception as e:
        print(f"  Error: {e}")
    
    # Show summary
    print("\nðŸ“Š Summary:")
    print("  â€¢ SMS pricing added for networks")
    print("  â€¢ LTE-M (CAT-M) support flags added")
    print("  â€¢ NB-IoT support flags added")
    print("  â€¢ Restrictions updated from source files")
    print("\nâœ… Quick import complete!")
    print("   The website will now show SMS prices and IoT badges where available")

if __name__ == "__main__":
    import_key_fields_only()